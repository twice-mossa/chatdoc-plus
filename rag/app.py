# rag/app.py
import os
import json
from datetime import datetime
import gradio as gr
from core import build_or_update_index, retrieve, build_context_and_citations, has_index
from llm_qwen import generate_with_cot, stream_generate_with_cot
from config import MAX_HISTORY_TURNS, MAX_NEW_TOKENS, MAX_CONTEXT_TOKENS, DEDUP_SIM_THRESHOLD, REWRITE_ENABLED, ALLOW_NO_RETRIEVAL_ANSWER, GRAPH_POLICY
from packing import pack_documents
from query import is_small_talk, is_simple_math, rewrite_with_history
from graph import run_graph, GraphOutput
from telemetry import span, write_telemetry

# â€”â€” ç³»ç»Ÿæç¤ºè¯ï¼ˆæœ‰/æ— æ£€ç´¢ä¸¤ç§ï¼‰â€”â€”
SYS_RAG = (
    "ä½ æ˜¯ä¸¥è°¨çš„ä¸­æ–‡é‡‘èåŠ©æ‰‹ï¼Œå¿…é¡»ä¾æ®æä¾›çš„ã€æ£€ç´¢ç‰‡æ®µã€‘å›ç­”ï¼›"
    "è‹¥ç‰‡æ®µä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜â€œæ ¹æ®ææ–™æ— æ³•ç¡®å®šâ€ã€‚"
    "å›ç­”è¦ç‚¹åŒ–ï¼Œå¹¶åœ¨æœ«å°¾ç”¨ [1][2]â€¦ æ ‡æ³¨å¼•ç”¨ç‰‡æ®µç¼–å·ã€‚"
)
SYS_PLAIN = (
    "ä½ æ˜¯ä¸­æ–‡é‡‘èåŠ©æ‰‹ã€‚å½“å‰æ²¡æœ‰æ£€ç´¢ç‰‡æ®µï¼Œè¯·åŸºäºå¸¸è¯†ç»™å‡ºç®€æ´ã€è¦ç‚¹åŒ–å›ç­”ï¼Œ"
    "å¹¶æç¤ºå†…å®¹å¯èƒ½ä¸å¤Ÿç²¾å‡†ã€‚"
)

def build_index_ui(file):
    build_or_update_index(file.name)
    return "âœ”ï¸ ç´¢å¼•å·²æ›´æ–°"


def build_indexes_ui(files):
    if not files:
        return "æœªé€‰æ‹©æ–‡ä»¶", []
    try:
        file_list = files if isinstance(files, list) else [files]
        for f in file_list:
            build_or_update_index(f.name)
        return "âœ”ï¸ ç´¢å¼•å·²æ›´æ–°", file_list
    except Exception as e:
        return f"âŒ ç´¢å¼•å¤±è´¥ï¼š{e}", []

def chat_ask(message, history):
    # history: list[tuple[str,str]] from Chatbot
    # æ—è·¯ï¼šå°èŠ/ç®€å•è®¡ç®—ä¸æ£€ç´¢ï¼Œç›´æ¥ç”Ÿæˆ
    if ALLOW_NO_RETRIEVAL_ANSWER and (is_small_talk(message) or is_simple_math(message)):
        history = history or []
        history_tail = history[-MAX_HISTORY_TURNS:]
        history_str = "\n\n".join([f"ç”¨æˆ·ï¼š{q}\nåŠ©æ‰‹ï¼š{a}" for q, a in history_tail]) if history_tail else ""
        prompt = (
            f"{SYS_PLAIN}\n\n" +
            (f"ã€å†å²å¯¹è¯ã€‘\n{history_str}\n\n" if history_str else "") +
            f"ã€é—®é¢˜ã€‘{message}\nã€å›ç­”ã€‘"
        )
        try:
            partial = ""
            for chunk in stream_generate_with_cot(prompt, max_new_tokens=MAX_NEW_TOKENS):
                partial = chunk
                yield (history + [(message, partial)], "", "", (message, partial), "")
            return
        except Exception as e:
            err = f"âŒ æ¨ç†å‡ºé”™ï¼š{e}"
            yield ((history or []) + [(message, err)], "", "", (message, err), "")
            return

    # æ­£å¸¸ï¼šå¯é€‰é‡å†™åæ£€ç´¢ï¼ˆè‹¥é…ç½® graphï¼Œåˆ™èµ°æœ€å°çŠ¶æ€æœºï¼‰
    if GRAPH_POLICY == "graph":
        for out in run_graph(message, history or []):
            if isinstance(out, GraphOutput):
                # æµå¼ä¸­é—´æ€
                cites_md = out.cites_md
                if cites_md:
                    cites_md = f"{cites_md}\n\nå¼•ç”¨æ¡æ•°ï¼š{out.cite_num}ï½œå¹³å‡ç½®ä¿¡åº¦ï¼š{out.avg_score:.2f}"
                yield ((history or []) + [(message, out.answer)], cites_md, "", (message, out.answer), cites_md)
        return

    rewritten = rewrite_with_history(message, history or []) if REWRITE_ENABLED else message
    trace = {"query": message}
    with span("retrieve1", trace):
        docs = retrieve(rewritten, k=4)
    history = history or []
    history_tail = history[-MAX_HISTORY_TURNS:]
    history_str = "\n\n".join([f"ç”¨æˆ·ï¼š{q}\nåŠ©æ‰‹ï¼š{a}" for q, a in history_tail]) if history_tail else ""

    if docs:
        with span("pack", trace):
            packed_docs, avg_score, cite_num = pack_documents(
                message, docs, max_context_tokens=MAX_CONTEXT_TOKENS, dedup_sim_threshold=DEDUP_SIM_THRESHOLD
            )
            context, cites_md = build_context_and_citations(packed_docs)
            if cites_md:
                cites_md = f"{cites_md}\n\nå¼•ç”¨æ¡æ•°ï¼š{cite_num}ï½œå¹³å‡ç½®ä¿¡åº¦ï¼š{avg_score:.2f}"
        prompt = (
            f"{SYS_RAG}\n\n" +
            (f"ã€å†å²å¯¹è¯ã€‘\n{history_str}\n\n" if history_str else "") +
            f"ã€æ£€ç´¢ç‰‡æ®µã€‘\n{context}\n\nã€é—®é¢˜ã€‘{message}\nã€å›ç­”ã€‘"
        )
    else:
        cites_md = ""
        prompt = (
            f"{SYS_PLAIN}\n\n" +
            (f"ã€å†å²å¯¹è¯ã€‘\n{history_str}\n\n" if history_str else "") +
            f"ã€é—®é¢˜ã€‘{message}\nã€å›ç­”ã€‘"
        )
    try:
        partial = ""
        with span("generate", trace):
            for chunk in stream_generate_with_cot(prompt, max_new_tokens=MAX_NEW_TOKENS):
                partial = chunk
                yield (history + [(message, partial)], cites_md, "", (message, partial), cites_md)
        answer = partial
    except Exception as e:
        answer = f"âŒ æ¨ç†å‡ºé”™ï¼š{e}"
        cites_md = ""
        yield ((history or []) + [(message, answer)], cites_md, "", (message, answer), cites_md)
    trace["cite_num"] = cite_num if docs else 0
    trace["avg_score"] = float(avg_score) if docs else 0.0
    write_telemetry(trace)

avatar_user = "rag/assets/user.png"
avatar_bot = "rag/assets/bot.png"
avatars = (avatar_user if os.path.exists(avatar_user) else None, avatar_bot if os.path.exists(avatar_bot) else None)

custom_css = """
.topbar{display:flex;gap:8px;align-items:center}
.attach-btn button,.link-btn button{min-width:32px;width:36px;height:36px}
.send-btn button{min-width:32px;width:40px;height:40px}
.clear-btn button{min-width:40px;width:56px;height:40px}
.msgbox textarea{min-height:44px;font-size:15px}
.composer{position:sticky;bottom:0;background:transparent;padding:6px 0}
.gr-chatbot{background:#0e0f13}
.gr-chatbot .message.user{justify-content:flex-end}
.gr-chatbot .message{display:flex}
.gr-chatbot .message .message-content{max-width:78%;border-radius:16px;padding:12px 14px}
.gr-chatbot .message.user .message-content{background:#2563eb;color:#fff}
.gr-chatbot .message.bot .message-content{background:#0b1221;border:1px solid #1f2937}
.cites{font-size:13px;opacity:0.9}
"""

with gr.Blocks(theme=gr.themes.Soft(), css=custom_css) as demo:
    gr.Markdown("### ChatDoc-Plus Â· é‡‘èæ–‡æ¡£é—®ç­”ï¼ˆRAG + Qwenï¼‰")

    with gr.Row(elem_classes=["topbar"]):
        status = gr.Textbox(label="ç´¢å¼•çŠ¶æ€", interactive=False)
    files_box = gr.Files(label="å·²ä¸Šä¼ ", interactive=False, height=60)

    chatbot = gr.Chatbot(label=None, height=560, avatar_images=avatars, show_copy_button=True)
    with gr.Accordion("è¯æ®ä¸å¼•ç”¨", open=False):
        cites = gr.Markdown(elem_classes=["cites"])
        with gr.Row():
            thumb_up = gr.Button("ğŸ‘", scale=0)
            thumb_down = gr.Button("ğŸ‘", scale=0)
            fix_btn = gr.Button("çº é”™", scale=0)
    last_pair = gr.State(("", ""))  # (q,a)
    last_cites = gr.State("")

    with gr.Row(elem_classes=["composer"]):
        attach2 = gr.UploadButton("ğŸ“", file_types=[".pdf"], file_count="multiple", elem_classes=["link-btn"], scale=0)
        msg = gr.Textbox(placeholder="åœ¨è¿™é‡Œè¾“å…¥ï¼ŒæŒ‰ Enter å‘é€â€¦", lines=2, show_label=False, elem_classes=["msgbox"])
        send = gr.Button("â¤", variant="primary", elem_classes=["send-btn"], scale=0)
        clear = gr.Button("ğŸ—‘", variant="secondary", elem_classes=["clear-btn"], scale=0)

    attach2.upload(build_indexes_ui, inputs=attach2, outputs=[status, files_box])

    def _clear_chat():
        return [], ""

    send.click(chat_ask, inputs=[msg, chatbot], outputs=[chatbot, cites, msg, last_pair, last_cites])
    msg.submit(chat_ask, inputs=[msg, chatbot], outputs=[chatbot, cites, msg, last_pair, last_cites])
    clear.click(_clear_chat, outputs=[chatbot, cites])

    def _log_feedback(polarity: int, pair: tuple[str, str], cites_text: str):
        try:
            os.makedirs("logs", exist_ok=True)
            rec = {
                "time": datetime.utcnow().isoformat(),
                "question": pair[0],
                "answer": pair[1],
                "citations": cites_text,
                "feedback": polarity,  # 1=up, -1=down, 0=fix
            }
            with open("logs/feedback.jsonl", "a", encoding="utf-8") as f:
                f.write(json.dumps(rec, ensure_ascii=False) + "\n")
            return "å·²è®°å½•åé¦ˆ"
        except Exception as e:
            return f"è®°å½•å¤±è´¥ï¼š{e}"

    fb_status = gr.Markdown()
    thumb_up.click(lambda p, c: _log_feedback(1, p, c), inputs=[last_pair, last_cites], outputs=fb_status)
    thumb_down.click(lambda p, c: _log_feedback(-1, p, c), inputs=[last_pair, last_cites], outputs=fb_status)
    def _fix(pair, cites_text):
        return _log_feedback(0, pair, cites_text)
    fix_btn.click(_fix, inputs=[last_pair, last_cites], outputs=fb_status)

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)
